def print_jittor_model_weights(jittor_model):
    """æ‰“å°Jittoræ¨¡å‹çš„æ‰€æœ‰æƒé‡ä¿¡æ¯"""
    
    print("="*80)
    print("JITTORæ¨¡å‹æƒé‡è¯¦æƒ…")
    print("="*80)
    
    total_params = 0
    
    for name, param in jittor_model.named_parameters():
        param_count = param.numel() if hasattr(param, 'numel') else param.size
        total_params += param_count
        
        print(f"å±‚åç§°: {name}")
        print(f"  å½¢çŠ¶: {param.shape}")
        print(f"  ç±»å‹: {param.dtype}")
        print(f"  å‚æ•°æ•°é‡: {param_count:,}")
        print(f"  æ•°å€¼èŒƒå›´: [{param.min().item():.6f}, {param.max().item():.6f}]")
        print(f"  æ•°å€¼å‡å€¼: {param.mean().item():.6f}")
        print(f"  æ•°å€¼æ ‡å‡†å·®: {param.std().item():.6f}")
        print("-" * 50)
    
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print("="*80)
def print_model_structure_and_weights(jittor_model):
    """åˆ†å±‚æ¬¡æ˜¾ç¤ºæ¨¡å‹ç»“æ„å’Œæƒé‡"""
    
    print("="*80)
    print("JITTORæ¨¡å‹ç»“æ„ä¸æƒé‡è¯¦æƒ…")
    print("="*80)
    
    def print_module_weights(module, module_name="", indent=0):
        """é€’å½’æ‰“å°æ¨¡å—æƒé‡"""
        prefix = "  " * indent
        
        # æ‰“å°å½“å‰æ¨¡å—ä¿¡æ¯
        if hasattr(module, '_parameters') and module._parameters:
            print(f"{prefix}ğŸ“ {module_name} ({type(module).__name__})")
            
            for param_name, param in module._parameters.items():
                if param is not None:
                    print(f"{prefix}  âš™ï¸  {param_name}: {param.shape} ({param.dtype})")
                    print(f"{prefix}     å‚æ•°é‡: {param.numel():,}")
                    print(f"{prefix}     èŒƒå›´: [{param.min().item():.4f}, {param.max().item():.4f}]")
                    print(f"{prefix}     å‡å€¼: {param.mean().item():.4f}")
        
        # é€’å½’å¤„ç†å­æ¨¡å—
        if hasattr(module, '_modules') and module._modules:
            for child_name, child_module in module._modules.items():
                if child_module is not None:
                    full_name = f"{module_name}.{child_name}" if module_name else child_name
                    print_module_weights(child_module, full_name, indent + 1)
    
    print_module_weights(jittor_model, "model")
    print("="*80)
def analyze_specific_layers(jittor_model):
    """åˆ†æç‰¹å®šå±‚çš„æƒé‡"""
    
    print("="*80)
    print("å…³é”®å±‚æƒé‡åˆ†æ")
    print("="*80)
    
    # åˆ†æPatchEmbedå±‚
    if hasattr(jittor_model, 'patch_embed'):
        print("ğŸ” PATCH EMBED å±‚åˆ†æ:")
        patch_embed = jittor_model.patch_embed
        
        if hasattr(patch_embed, 'proj'):
            proj = patch_embed.proj
            print(f"  Conv2dæƒé‡: {proj.weight.shape}")
            print(f"  Conv2dé…ç½®: in_channels={proj.in_channels}, out_channels={proj.out_channels}")
            print(f"  kernel_size: {proj.kernel_size}, stride: {proj.stride}")
            print(f"  æƒé‡ç»Ÿè®¡: æœ€å°å€¼={proj.weight.min().item():.6f}, æœ€å¤§å€¼={proj.weight.max().item():.6f}")
            
            if proj.bias is not None:
                print(f"  åç½®: {proj.bias.shape}, èŒƒå›´=[{proj.bias.min().item():.6f}, {proj.bias.max().item():.6f}]")
            else:
                print("  åç½®: None")
        
        print("-" * 50)
    
    # åˆ†æä½ç½®ç¼–ç 
    if hasattr(jittor_model, 'pos_embed'):
        print("ğŸ” ä½ç½®ç¼–ç åˆ†æ:")
        pos_embed = jittor_model.pos_embed
        print(f"  å½¢çŠ¶: {pos_embed.shape}")
        print(f"  ç»Ÿè®¡: å‡å€¼={pos_embed.mean().item():.6f}, æ ‡å‡†å·®={pos_embed.std().item():.6f}")
        print("-" * 50)
    
    # åˆ†æç±»åˆ«token
    if hasattr(jittor_model, 'cls_token'):
        print("ğŸ” CLS Token åˆ†æ:")
        cls_token = jittor_model.cls_token
        print(f"  å½¢çŠ¶: {cls_token.shape}")
        print(f"  ç»Ÿè®¡: å‡å€¼={cls_token.mean().item():.6f}, æ ‡å‡†å·®={cls_token.std().item():.6f}")
        print("-" * 50)
    
    # åˆ†æTransformerå—
    if hasattr(jittor_model, 'blocks'):
        print("ğŸ” TRANSFORMER å—åˆ†æ:")
        print(f"  æ€»å—æ•°: {len(jittor_model.blocks)}")
        
        for i, block in enumerate(jittor_model.blocks[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªå—
            print(f"  Block {i}:")
            
            # æ³¨æ„åŠ›å±‚
            if hasattr(block, 'attn'):
                attn = block.attn
                if hasattr(attn, 'qkv'):
                    print(f"    QKVæƒé‡: {attn.qkv.weight.shape}")
                if hasattr(attn, 'proj'):
                    print(f"    è¾“å‡ºæŠ•å½±: {attn.proj.weight.shape}")
            
            # MLPå±‚
            if hasattr(block, 'mlp'):
                mlp = block.mlp
                if hasattr(mlp, 'fc1'):
                    print(f"    MLP FC1: {mlp.fc1.weight.shape}")
                if hasattr(mlp, 'fc2'):
                    print(f"    MLP FC2: {mlp.fc2.weight.shape}")
        
        if len(jittor_model.blocks) > 2:
            print(f"    ... è¿˜æœ‰ {len(jittor_model.blocks) - 2} ä¸ªå—")
        
        print("-" * 50)
    
    # åˆ†æåˆ†ç±»å¤´
    if hasattr(jittor_model, 'head'):
        print("ğŸ” åˆ†ç±»å¤´åˆ†æ:")
        head = jittor_model.head
        if hasattr(head, 'weight'):
            print(f"  æƒé‡å½¢çŠ¶: {head.weight.shape}")
            print(f"  ç»Ÿè®¡: å‡å€¼={head.weight.mean().item():.6f}, æ ‡å‡†å·®={head.weight.std().item():.6f}")
        print("-" * 50)
    
    print("="*80)
def compare_weights_after_conversion(pytorch_model, jittor_model):
    """è½¬æ¢åæƒé‡å¯¹æ¯”åˆ†æ"""
    
    print("="*80)
    print("PYTORCH vs JITTOR æƒé‡å¯¹æ¯”")
    print("="*80)
    
    # è·å–PyTorchçŠ¶æ€å­—å…¸
    pt_state_dict = pytorch_model.state_dict()
    
    # å¯¹æ¯”å…³é”®å±‚
    comparison_results = []
    
    for name, jt_param in jittor_model.named_parameters():
        if name in pt_state_dict:
            pt_param = pt_state_dict[name]
            
            # è½¬æ¢ä¸ºnumpyè¿›è¡Œå¯¹æ¯”
            pt_numpy = pt_param.detach().cpu().numpy()
            jt_numpy = jt_param.numpy()
            
            # è®¡ç®—å·®å¼‚
            if pt_numpy.shape == jt_numpy.shape:
                diff = np.abs(pt_numpy - jt_numpy)
                max_diff = np.max(diff)
                mean_diff = np.mean(diff)
                
                result = {
                    'name': name,
                    'shape': pt_numpy.shape,
                    'max_diff': max_diff,
                    'mean_diff': mean_diff,
                    'match': max_diff < 1e-6
                }
            else:
                result = {
                    'name': name,
                    'shape_pt': pt_numpy.shape,
                    'shape_jt': jt_numpy.shape,
                    'match': False,
                    'error': 'Shape mismatch'
                }
            
            comparison_results.append(result)
    
    # æ‰“å°å¯¹æ¯”ç»“æœ
    for result in comparison_results:
        print(f"å‚æ•°: {result['name']}")
        
        if 'error' in result:
            print(f"  âŒ {result['error']}")
            print(f"  PyTorchå½¢çŠ¶: {result.get('shape_pt', 'N/A')}")
            print(f"  Jittorå½¢çŠ¶: {result.get('shape_jt', 'N/A')}")
        else:
            status = "âœ… åŒ¹é…" if result['match'] else "âš ï¸  æœ‰å·®å¼‚"
            print(f"  {status}")
            print(f"  å½¢çŠ¶: {result['shape']}")
            print(f"  æœ€å¤§å·®å¼‚: {result['max_diff']:.2e}")
            print(f"  å¹³å‡å·®å¼‚: {result['mean_diff']:.2e}")
        
        print("-" * 50)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_params = len(comparison_results)
    matched_params = sum(1 for r in comparison_results if r.get('match', False))
    
    print(f"æ€»å‚æ•°æ•°: {total_params}")
    print(f"åŒ¹é…å‚æ•°: {matched_params}")
    print(f"åŒ¹é…ç‡: {matched_params/total_params*100:.1f}%")
    print("="*80)
import tempfile
import numpy as np
import torch
import jittor as jt
def convert_pytorch_to_jittor_with_analysis(pytorch_model, jittor_model):
    """è½¬æ¢å¹¶åˆ†ææ¨¡å‹æƒé‡"""
    
    print("å¼€å§‹è½¬æ¢PyTorchæ¨¡å‹åˆ°Jittor...")
    
    # è½¬æ¢å‰åˆ†æ
    # print("\nğŸ“Š è½¬æ¢å‰Jittoræ¨¡å‹çŠ¶æ€:")
    # print_jittor_model_weights(jittor_model)
    
    # æ‰§è¡Œè½¬æ¢
    with tempfile.NamedTemporaryFile() as tmp:
        torch.save(pytorch_model.state_dict(), tmp.name)
        pt_state_dict = torch.load(tmp.name, map_location='cpu')
        
        successful_loads = 0
        failed_loads = 0
        
        for name, param in jittor_model.named_parameters():
            if name in pt_state_dict:
                try:
                    tensor = pt_state_dict[name].numpy()
                    param.assign(jt.array(tensor))
                    successful_loads += 1
                    # print(f"âœ… æˆåŠŸåŠ è½½: {name} {tensor.shape}")
                except Exception as e:
                    failed_loads += 1
                    print(f"âŒ åŠ è½½å¤±è´¥: {name} - {e}")
            else:
                failed_loads += 1
                print(f"âš ï¸  æœªæ‰¾åˆ°å‚æ•°: {name}")
        
        print(f"\nåŠ è½½ç»Ÿè®¡: æˆåŠŸ {successful_loads}, å¤±è´¥ {failed_loads}")
    
    # # è½¬æ¢ååˆ†æ
    # print("\nğŸ“Š è½¬æ¢åè¯¦ç»†åˆ†æ:")
    # print_model_structure_and_weights(jittor_model)
    
    # print("\nğŸ“Š å…³é”®å±‚åˆ†æ:")
    # analyze_specific_layers(jittor_model)
    
    # print("\nğŸ“Š æƒé‡å¯¹æ¯”åˆ†æ:")
    # compare_weights_after_conversion(pytorch_model, jittor_model)
    
    return jittor_model

